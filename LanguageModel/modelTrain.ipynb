{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dda67099",
   "metadata": {},
   "source": [
    "### Trabalho Pratico NLP 2021/2\n",
    "##### Nome: Guilherme Cramer \n",
    "##### Matricula: 2021666152"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8410c53e",
   "metadata": {},
   "source": [
    "#### Treinamento do modelo de Linguagem. \n",
    "Primeiramente vamos importar os pacotes necessários. Será usado a biblioteca \"gensin.Word2vec\" para o modelo de linguagem (Cbow e Skip-gran). \n",
    "\n",
    "A biblioteca \"spacy\" será usada para o preprocessamento do texto. No preprocessamento, foi escolhido 4 formas de tratamento. A primeira transforma a palavram em minúscula; a segunda elimina as palavras que não tem significado semântico, como palavras de conexões e artigos (\"the\" , \"a\",... etc). A terceira elimina as pontuações; já o quarto processamento realiza a \"lemmarização\" da palavra, ou seja, transforma ela em sua forma mais original. Por exemplo transforma \"working\" em \"work\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60470275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7af12c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cleanData(doc,stemming = False):\n",
    "    doc = doc.lower()\n",
    "    doc = nlp(doc)\n",
    "    tokens = [tokens.lower_ for tokens in doc]\n",
    "    tokens = [tokens for tokens in doc if (tokens.is_stop == False)]\n",
    "    tokens = [tokens for tokens in tokens if (tokens.is_punct == False)]\n",
    "    final_token = [token.lemma_ for token in tokens]\n",
    "    \n",
    "    return \" \".join(final_token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589a17ca",
   "metadata": {},
   "source": [
    "Leitura dos dados sem tratamentos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8459c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:\\\\Users\\\\gcram\\\\Documents\\\\Datasets\\\\text8\\\\text8'\n",
    "with open(data_path) as f:\n",
    "    lines = f.readlines()\n",
    "data = lines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a22a28e",
   "metadata": {},
   "source": [
    "Como o tamanho do dataset é muito grande para o modelo em ingles do \"spacy\", o preprocessamento foi feito em partes. Mas não altera em nada.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a60e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_s = data.split(' ')\n",
    "N = len(data_s)\n",
    "bs = 100000\n",
    "n_batch = int(len(data_s)/bs) + 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5be346b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ini = 0\n",
    "res = ''\n",
    "for batch in range(n_batch):\n",
    "    end = ini + bs\n",
    "    if end < N:\n",
    "        data_bat = data[ini:end]\n",
    "    else:\n",
    "        data_bat = data[ini:]\n",
    "    d = ''.join(data_bat)\n",
    "    d_procss = cleanData(d)\n",
    "    res = res + ' ' + ''.join(d_procss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7359e26d",
   "metadata": {},
   "source": [
    "Salva os dados já processados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e02d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_save = 'C:\\\\Users\\\\gcram\\\\Documents\\\\Datasets\\\\text8\\\\text8_preprocss'\n",
    "with open(data_save, 'w') as f:\n",
    "    f.write(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a315359",
   "metadata": {},
   "source": [
    "Carrega os dados para serem passados para o modelo treinar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddfd340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Text8Corpus('C:\\\\Users\\\\gcram\\\\Documents\\\\Datasets\\\\text8\\\\text8_preprocss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fad9ab",
   "metadata": {},
   "source": [
    "São criados e treinados algums modelos variando-se os parâmetros de tamanho da janela e também o tamanho do vetor de representação. Apesar de nas instruções do Trabalho ter pedido para variar o \"training size\", eu não entendi o que seria isso. Creio que a variação do tamanho do vetor de representação também seja bem interessante. \n",
    "Após o treinamento o modelo é salvo localmente para ser avaliado no outro código. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "654ac580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,glob\n",
    "os.chdir(\"C:\\\\Users\\\\gcram\\\\Documents\\\\GitHub\\\\NLP\\\\LanguageModel\\\\\")\n",
    "models = glob.glob(\"*.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63c633e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "d['skip-gram'] = 1\n",
    "d['cbow'] = 0\n",
    "\n",
    "for ws in [5,10,20,100]:\n",
    "    for ts in [20,50,100,200]:\n",
    "        for method in ['skip-gram','cbow']:\n",
    "            model_name = f\"word2vec{ws}_{ts}_{method}.model\"\n",
    "            if model_name in models:\n",
    "                continue\n",
    "            model = Word2Vec(sentences=data, \n",
    "                 vector_size=ts,\n",
    "                 window=ws, \n",
    "                 min_count=1, \n",
    "                 workers=4,\n",
    "                sg=d[method])\n",
    "            model.save(model_name)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd87344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3c76288",
   "metadata": {},
   "source": [
    "#### Referências: \n",
    "https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Text8Corpus\n",
    "https://www.kaggle.com/theainerd/beginners-s-guide-to-nlp-using-spacy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
